import os
import numpy as np
import librosa
import torch
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.sampler import Sampler
import pandas as pd

"""
Just to make sure on the interface, what are you thinking for the output of the dataloader?
    padded_sequences (np.array batch_size x max_seq_len x mel_features_size), 
    seq_lengths (np.array batch_size), 
    labels (np.array, batch_size)
"""
__all__ = [
    'SpeakerDataset',
    'BalancedSpeakerSampler',
]

class SpeakerDataset(Dataset):
    def __init__(self, csv_index, data_path, mel_transformer, 
                 speaker_id_map = None, 
                 reindex_speakers = True, 
                 sample_length = 16384):
        """
        csv_index - path to an index file that has rows of 'speaker id, sample'; speaker id
            should be an int, sample should be a file path
        data_path - a root path to be joined to file paths in csv_index
        speaker_id_map - dictionary of {dataset_speaker_id:new_speaker_id} transforms; will
            be autogenerated by reindex_speakers if set
        reindex_speakers - reindex speaker labels to 0..[#speakers-1] ? default True
        """
        if speaker_id_map is not None and reindex_speakers is True:
            raise ValueError("speaker_id_map and reindex_speakers should not both be set.")
        self.csv_index = csv_index
        self.data_path = data_path
        self.reindex_speakers = reindex_speakers
        self.mel_transformer = mel_transformer
        self.speaker_id_map = speaker_id_map
        self.sample_length = sample_length
        self._load_and_parse_index()

    def _load_and_parse_index(self):
        speaker_df = pd.read_csv(self.csv_index, header=None)
        self.speaker_df=speaker_df
        if self.reindex_speakers is True:
            old_ids = sorted(list(set(speaker_df[0])))
            self.speaker_id_map = {old:new for old, new in zip(old_ids, range(len(old_ids)))}
        elif self.speaker_id_map is None:
            self.speaker_id_map = {a:a for a in sorted(list(set(speaker_df[0])))}
        self.speaker_idlist = [self.speaker_id_map[i] for i in self.speaker_df[0]]
        
    def __len__(self):
        return self.speaker_df.shape[0]
    
    def __getitem__(self, idx):
        fullpath = os.path.join(self.data_path, self.speaker_df.iloc[idx,1])
        speaker_id = self.speaker_df.iloc[idx,0]
        samples, rate = librosa.load(fullpath)
        if rate != 22050:
            raise ValueError("Sample at {} has wrong sample rate (expected 22050, got {})".format(fullpath, rate))
        if len(samples)<self.sample_length:
            rv, padding = np.hstack((samples, np.zeros(self.sample_length-len(samples)))), self.sample_length-len(samples)
        else:
            start = np.random.randint(low=0, high=len(samples)-self.sample_length)
            stop = start + self.sample_length
            rv,padding = samples[start:stop], 0
        samples = torch.from_numpy(rv.reshape(1, -1))
        samples = torch.clamp(samples, -1.0, 1.0)
        ms = self.mel_transformer(samples)
        return (ms.squeeze().permute(1,0), padding, self.speaker_id_map[speaker_id])
    
class BalancedSpeakerSampler(Sampler):
    def __init__(self, speaker_ids, speakers_per_batch, samples_per_speaker, batches_per_epoch):
        self.speaker_ids = np.array(speaker_ids)
        if len(self.speaker_ids.shape)>1:
            raise ValueError("Needed a 1d array")
        self.speakers_per_batch = speakers_per_batch
        self.samples_per_speaker = samples_per_speaker
        self.batches_per_epoch = batches_per_epoch
    def __len__(self):
        return self.batches_per_epoch
    
    def __iter__(self):
        # this is pretty dumb, we're going to pick `speakers_per_batch` speakers at random from the list,
        # then pick `samples_per_speaker` samples from those, and return them; no more guarantees
        speakerset = list(set(self.speaker_ids))
        def get_indexes():
            chosen_speakers = np.random.choice(speakerset, size=self.speakers_per_batch)
            rv = []
            for speaker in chosen_speakers:
                speaker_batch = np.random.choice(np.where(self.speaker_ids==speaker)[0], size=self.samples_per_speaker)
                rv.extend(speaker_batch)
            return rv
        thelist = (i for sublist in [get_indexes() for _ in range(self.batches_per_epoch)] for i in sublist)
        return iter(thelist)
    